### 📦 **Día 1 – Preparación (setup del entorno)**

- [x]  Crear carpeta del proyecto → `portfolio_legalbot/`.
- [x]  Inicializar repo con `git init` y crear `.gitignore` (añadir `.venv`, `__pycache__`, `.db`, etc.).
- [x]  Crear entorno virtual: `python -m venv .venv`.
- [x]  Activar entorno virtual.
    - Windows: `.venv\Scripts\activate`
    - Mac/Linux: `source .venv/bin/activate`
- [x]  Instalar librerías:
    - `pip install fastapi uvicorn[standard] transformers torch PyMuPDF docx2txt sqlite-utils`
- [x]  Crear estructura de carpetas:
    
    ```
    back/
    ├── app/
    │   ├── main.py
    │   ├── demo_dataset.py
    │   ├── ingestion.py
    │   ├── classification.py
    │   ├── search.py
    │   └── database.py
    ├── uploads/
    ├── documents.db
    ├── requirements.txt
    └── README.md
    
    ```
    
- [x]  Definir categorías legales en `classification.py`:
    
    ```python
    LEGAL_CATEGORIES = ["Contratos", "Sentencias", "Normativas", "Licencias", "Otros"]
    
    ```
    

---

### 📂 **Día 2 – Dataset demo y base de datos**

- [ ]  Crear `demo_dataset.py` con lista de 10 documentos falsos (strings de texto).
- [ ]  Diseñar esquema de la tabla SQLite en `database.py`:
    - id (int, autoincrement)
    - title (str)
    - text (str)
    - category (str)
- [ ]  Crear funciones de base de datos:
    - `init_db()` → inicializar base si no existe, con manejo de errores.
    - `insert_document(title, text, category)` → insertar registros, con logging de inserciones y excepciones.
- [ ]  Endpoint `POST /load_demo/`:
    - [ ]  Llamar a `init_db()`
    - [ ]  Insertar los 10 documentos falsos
    - [ ]  Devolver cuántos documentos fueron cargados
    - [ ]  Loggear acciones y errores

---

### 📑 **Día 3 – Ingesta de documentos (modular y robusta)**

- [ ]  Crear `ingestion.py`
- [ ]  Funciones descriptivas para extracción de texto:
    - `extract_text_from_pdf(path)` → PyMuPDF (`fitz`)
    - `extract_text_from_docx(path)` → docx2txt
    - `extract_text_from_txt(path)` → lectura de archivo plano
- [ ]  `extract_text_from_file(path)` → detectar tipo de archivo y usar la función adecuada, con validación de extensión y tamaño
- [ ]  Endpoint `POST /upload_document/`:
    - [ ]  Recibir archivo (`UploadFile`)
    - [ ]  Guardarlo en `/uploads/`
    - [ ]  Extraer texto con `extract_text_from_file()`
    - [ ]  Manejar errores de archivos no válidos
    - [ ]  Devolver texto y mensajes de error si aplica

---

### 🧠 **Día 4 – Clasificación**

- [ ]  Instalar Hugging Face pipeline:

```python
from transformers import pipeline
classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli")

```

- [ ]  Crear `classify_text(text)` en `classification.py`:
    - Pasar `text` + `LEGAL_CATEGORIES` (en `constants.py`)
    - Devolver categoría con score más alto
    - Manejar errores del pipeline y loggear
- [ ]  Modificar endpoint `/upload_document/`:
    - Extraer texto
    - Clasificar con `classify_text(text)`
    - Guardar en DB (`insert_document()`)
    - Retornar categoría detectada con logging de éxito/fallo

---

### 🔎 **Día 5 – Búsqueda y listado profesional**

- [ ]  Crear `search.py`
- [ ]  Endpoint `GET /list_documents/`:
    - Listar todos los documentos
    - Filtrar opcionalmente por categoría (`?category=Contratos`)
- [ ]  Endpoint `GET /search_documents/`:
    - Recibir `query`
    - Validar input y tamaño
    - Buscar coincidencias con `LIKE '%query%'` en texto
    - Retornar documentos que contengan la palabra
- [ ]  Añadir logs de búsquedas y errores

---

### 🌐 **Día 6 – Frontend mínimo y UX profesional**

- [x]  Crear carpeta `static/`:

```
portfolio_legalbot/
└── static/
    ├── index.html
    └── style.css

```

- [ ]  `index.html`:
    - Formulario de subida con indicador de carga y mostrar categoría detectada
    - Input de búsqueda con tabla de resultados y filtro por categoría
    - Mensajes de error claros
- [ ]  `style.css`:
    - Colores suaves para categorías
    - Tipografía legible y espaciado adecuado
- [ ]  Conexión con endpoints usando JS (`fetch`):
    - `POST /upload_document/`
    - `GET /list_documents/`
    - `GET /search_documents/?query=`
- [ ]  Servir archivos estáticos desde FastAPI:

```python
from fastapi.staticfiles import StaticFiles
app.mount("/", StaticFiles(directory="static", html=True), name="static")

```

- [ ]  Probar flujo completo en navegador
- [ ]  Logs y manejo de errores visibles en frontend

---

### 🚀 **Día 7 – Demo final profesional**

- [ ]  Llamar a `POST /load_demo/` para precargar dataset
- [ ]  Flujo de demo:
    - Subir archivo → ver cómo se clasifica
    - Listar documentos y verificar categorías
    - Buscar término → mostrar resultados
- [ ]  Crear `run_demo.py`:
    - Ejecuta `/load_demo/`
    - Sube archivo de prueba
    - Realiza búsqueda de ejemplo
    - Permite demo completa con un comando
- [ ]  Documentación en `README.md`:
    - Instalación y requisitos (`pip install -r requirements.txt`)
    - Cómo correr FastAPI (`uvicorn app.main:app --reload`)
    - Ejemplos de endpoints (`curl` o Postman)
    - Flujo completo paso a paso
    - Mencionar documentación automática `/docs` y `/redoc`
- [ ]  Preparar guion demo oral:
    - Presentar problema
    - Subir archivo → clasificación automática
    - Buscar y listar documentos
- [ ]  Tests básicos:
    - Unit test para `extract_text_from_file()`
    - Unit test para `classify_text()`
- [ ]  Seguridad mínima:
    - Limitar tamaño máximo de archivo
    - Validar inputs de búsqueda (`query`)